{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.distributions import Exponential\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.datasets import make_circles\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "labels = []\n",
    "\n",
    "n=1\n",
    "while n < 1000: \n",
    "    x = random.randint(0,1)\n",
    "    if x == 0:\n",
    "        values.append(numpy.random.poisson(2))\n",
    "    if x == 1:\n",
    "        values.append(numpy.random.poisson(6))\n",
    "\n",
    "    labels.append(x)\n",
    "\n",
    "    n = n + 1\n",
    "\n",
    "values = numpy.array(values)\n",
    "labels = numpy.array(labels)\n",
    "print(labels)\n",
    "\n",
    "data = pd.DataFrame({\"values\": values, \"labels\": labels})\n",
    "X = torch.from_numpy(values).type(torch.float)\n",
    "y = torch.from_numpy(labels).type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2, # 20% test, 80% train\n",
    "                                                    random_state=42) # make the random split reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_poisson_relaxed(lmbd, num_samples=1000, temperature = 1e-2):\n",
    "    sampler = torch.empty(num_samples)\n",
    "    z = Exponential(lmbd).rsample(sampler.size())\n",
    "    t = torch.cumsum(z, 0)\n",
    "    relaxed_indicator = torch.sigmoid((1.0 - t) / temperature)\n",
    "    N = relaxed_indicator.sum()\n",
    "    return N\n",
    "\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "class CircleModelV0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2. Create 2 nn.Linear layers capable of handling X and y input and output shapes\n",
    "        self.layer_1 = nn.Linear(in_features=1, out_features=20) # takes in 2 features (X), produces 5 features\n",
    "        self.layer_2 = nn.Linear(in_features=20, out_features=10) # takes in 5 features, produces 1 feature (y)\n",
    "        self.layer_3 = nn.Linear(in_features=10, out_features=1) # takes in 5 features, produces 1 feature (y)\n",
    "        # self.layer_4 = nn.Linear(in_features=10, out_features=1) # takes in 5 features, produces 1 feature (y)\n",
    "        \n",
    "\n",
    "    \n",
    "    # 3. Define a forward method containing the forward pass computation\n",
    "    def forward(self, x):\n",
    "        # print(x)\n",
    "        # x.numpy\n",
    "        # print(x)\n",
    "        # print(x.size())\n",
    "        for i in range(x.size(dim=0)):\n",
    "            y = x[i].item()\n",
    "            # print(y) \n",
    "            x[i] = sample_poisson_relaxed(y+0.0001) #added a small decimal to counteract errors arising from a lambda=0\n",
    "        \n",
    "        # print(x)\n",
    "        rx = x\n",
    "        rx = rx.view(rx.size(dim =0),1)\n",
    "        # print(rx)\n",
    "        # print(rx.size())\n",
    "        \n",
    "\n",
    "        # Return the output of layer_2, a single feature, the same shape as y\n",
    "        # rx = self.layer_1(rx)\n",
    "        # print(1)\n",
    "        # rx = self.layer_2(torch.relu(rx))\n",
    "        # print(2)\n",
    "        # rx = self.layer_3(torch.relu(rx))\n",
    "        # return(rx)\n",
    "        return self.layer_3(torch.relu(self.layer_2(torch.relu(self.layer_1(rx))))) # computation goes through layer_1 first then the output of layer_1 goes through layer_2\n",
    "\n",
    "def makeModel():\n",
    "    return CircleModelV0().to(device)\n",
    "# 4. Create an instance of the model and send it to target device\n",
    "# model_0 = CircleModelV0().to(device)\n",
    "# model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Put data to target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "noises = []\n",
    "accuracy = []\n",
    "finalaccuracy = []\n",
    "finalnoise = []\n",
    "\n",
    "# Build training and evaluation loop\n",
    "for x in range(10):\n",
    "    model_0 = makeModel()\n",
    "    print(model_0)\n",
    "    loss_fn = nn.BCEWithLogitsLoss() # BCEWithLogitsLoss = sigmoid built-in\n",
    "\n",
    "    # Create an optimizer\n",
    "    optimizer = torch.optim.SGD(params=model_0.parameters(), \n",
    "                                lr=0.1)\n",
    "    for epoch in range(epochs):\n",
    "        ### Training\n",
    "        model_0.train()\n",
    "\n",
    "        # 1. Forward pass (model outputs raw logits)\n",
    "        y_logits = model_0(X_train).squeeze() # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device \n",
    "        y_pred = torch.round(torch.sigmoid(y_logits)) # turn logits -> pred probs -> pred labls\n",
    "    \n",
    "        # 2. Calculate loss/accuracy\n",
    "        # loss = loss_fn(torch.sigmoid(y_logits), # Using nn.BCELoss you need torch.sigmoid()\n",
    "        #                y_train) \n",
    "        loss = loss_fn(y_logits, # Using nn.BCEWithLogitsLoss works with raw logits\n",
    "                    y_train) \n",
    "        acc = accuracy_fn(y_true=y_train, \n",
    "                        y_pred=y_pred) \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backwards\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        ### Testing\n",
    "        model_0.eval()\n",
    "        with torch.inference_mode():\n",
    "            # 1. Forward pass\n",
    "            test_logits = model_0(X_test).squeeze() \n",
    "            test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "            # 2. Caculate loss/accuracy\n",
    "            test_loss = loss_fn(test_logits,\n",
    "                                y_test)\n",
    "            test_acc = accuracy_fn(y_true=y_test,\n",
    "                                y_pred=test_pred)\n",
    "\n",
    "        # Print out what's happening every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")\n",
    "        noises.append(-x)\n",
    "        accuracy.append(acc)\n",
    "    finalaccuracy.append(acc)\n",
    "    finalnoise.append(-x)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
